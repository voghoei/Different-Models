{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-dd7565c2534b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;31m#data = load('jsb')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'synthetic'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mipdb\u001b[0m\u001b[1;33m;\u001b[0m \u001b[0mipdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-dd7565c2534b>\u001b[0m in \u001b[0;36mload\u001b[1;34m(dset)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dim_observations'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmusicdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'dim_observations'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mdset\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'synthetic'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloadSyntheticData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Invalid dataset: '\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mdset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-dd7565c2534b>\u001b[0m in \u001b[0;36mloadSyntheticData\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mloadSyntheticData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mcurdir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurdir\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/synthetic.pkl'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Reloading...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def simulateLinearData(N, T, DIM):\n",
    "    \"\"\" Synthetic data generated according to a first order linear Markov process \"\"\"\n",
    "    z    = np.random.randn(N, DIM)\n",
    "    zlist= [np.copy(z)[:,None,:]]\n",
    "    W    = 0.1*np.random.randn(DIM,DIM)\n",
    "    for t in range(T-1):\n",
    "        z_next = np.dot(z,W) \n",
    "        zlist.append(np.copy(z_next)[:,None,:])\n",
    "        z      = z_next\n",
    "    Z   = np.concatenate(zlist, axis=1)\n",
    "    X   = Z + 4*np.random.randn(*Z.shape) \n",
    "    return X, Z\n",
    "\n",
    "def loadSyntheticData():\n",
    "    curdir = os.path.dirname(os.path.realpath(__file__))\n",
    "    if os.path.exists(curdir+'/synthetic.pkl'): \n",
    "        print ('Reloading...')\n",
    "        return readPickle(curdir+'/synthetic.pkl')[0]\n",
    "    \"\"\" Generate simple synthetic data \"\"\"\n",
    "    params  = {}\n",
    "    params['train']  = 10000\n",
    "    params['valid']  = 1000\n",
    "    params['test']   = 1000\n",
    "    N       = np.sum([params[k] for k in params])\n",
    "    T       = 10\n",
    "    DIM_OBS = 3\n",
    "    np.random.seed(0)\n",
    "    data, data_Z     = simulateLinearData(N, T, DIM_OBS)\n",
    "    \"\"\"\n",
    "    Split into train/valid/test\n",
    "    \"\"\"\n",
    "    shufidx = np.random.permutation(N)\n",
    "    indices = {}\n",
    "    indices['train'] = shufidx[:params['train']]\n",
    "    indices['valid'] = shufidx[params['train']:params['train']+params['valid']]\n",
    "    indices['test']  = shufidx[params['train']+params['valid']:]\n",
    "    \"\"\"\n",
    "    Setup dataset to return\n",
    "    \"\"\"\n",
    "    dataset = {}\n",
    "    for k in ['train','valid','test']:\n",
    "        dataset[k]   = {}\n",
    "        dataset[k]['tensor']   = data[indices[k]] \n",
    "        dataset[k]['tensor_Z'] = data_Z[indices[k]] \n",
    "        dataset[k]['mask']     = np.ones_like(dataset[k]['tensor'][:,:,0]) \n",
    "    dataset['data_type']            = 'real'\n",
    "    dataset['dim_observations']     = 3\n",
    "    savePickle([dataset],curdir+'/synthetic.pkl')\n",
    "    print ('Saving...')\n",
    "    return dataset\n",
    "\n",
    "def load(dset):\n",
    "    if dset   in ['jsb','nottingham','musedata','piano']:\n",
    "        musicdata = loadDataset(dset)\n",
    "        dataset   = {}\n",
    "        for k in ['train','valid','test']:\n",
    "            dataset[k] = {}  \n",
    "            dataset[k]['tensor'] = musicdata[k] \n",
    "            dataset[k]['mask']   = musicdata['mask_'+k]\n",
    "        dataset['data_type']        = musicdata['data_type']\n",
    "        dataset['dim_observations'] = musicdata['dim_observations']\n",
    "    elif dset == 'synthetic':\n",
    "        dataset = loadSyntheticData()\n",
    "    else:\n",
    "        raise ValueError('Invalid dataset: '+dset)\n",
    "    return dataset\n",
    "\n",
    "if __name__=='__main__':\n",
    "    #data = load('jsb')\n",
    "    data = load('synthetic')\n",
    "    import ipdb; ipdb.set_trace()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
